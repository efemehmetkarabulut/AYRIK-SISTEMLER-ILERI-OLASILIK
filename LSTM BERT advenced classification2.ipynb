{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjKrahH0qTGyu7pr08xQB0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efemehmetkarabulut/AYRIK-SISTEMLER-ILERI-OLASILIK/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "RIdYb4rbW1TR",
        "outputId": "09006713-3473-4faf-d3a6-161d615d9cea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'bbc_data_1_2.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d3bfcdeca5ef>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Ana fonksiyonu çağırma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d3bfcdeca5ef>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Adım 1: Veri setini indirme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Adım 2: Veriyi temizleme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d3bfcdeca5ef>\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/bbc_data_1_2.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bbc_data_1_2.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bbc_data_1_2.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Concatenate, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Adım 1: Veri setini indiren fonksiyon\n",
        "def download_dataset():\n",
        "    file_path = '/content/bbc_data_1_2.xlsx'\n",
        "    data = pd.read_excel('bbc_data_1_2.xlsx')\n",
        "    return data\n",
        "\n",
        "# Adım 2: Veriyi temizleyen fonksiyon\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Noktalama işaretlerini kaldırma\n",
        "    text = re.sub(r'\\s+', ' ', text)    # Birden fazla boşluğu tek boşlukla değiştirme\n",
        "    text = text.lower()                 # Metni küçük harfe dönüştürme\n",
        "    return text\n",
        "\n",
        "# Adım 3: Eksik değerleri doldurma\n",
        "def fill_missing_values(data):\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "# Adım 4: BERT + LSTM Ensemble Modeli Oluşturma\n",
        "def create_ensemble_model():\n",
        "    # BERT modeli\n",
        "    bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_input_ids = Input(shape=(128,), dtype=tf.int32, name='input_ids')\n",
        "    bert_attention_mask = Input(shape=(128,), dtype=tf.int32, name='attention_mask')\n",
        "    bert_output = bert_model(bert_input_ids, attention_mask=bert_attention_mask).last_hidden_state\n",
        "    bert_pooling = GlobalMaxPooling1D()(bert_output)\n",
        "\n",
        "    # LSTM modeli\n",
        "    lstm_input = Input(shape=(128,), name='lstm_input')\n",
        "    embedding = Embedding(input_dim=5000, output_dim=128, input_length=128)(lstm_input)\n",
        "    lstm_output = LSTM(64, return_sequences=True)(embedding)\n",
        "    lstm_pooling = GlobalMaxPooling1D()(lstm_output)\n",
        "\n",
        "    # Ensemble (BERT ve LSTM çıktılarının birleştirilmesi)\n",
        "    merged_output = Concatenate()([bert_pooling, lstm_pooling])\n",
        "\n",
        "    # Tam bağlantılı katman ve sınıflandırma\n",
        "    dense_output = Dense(64, activation='relu')(merged_output)\n",
        "    final_output = Dense(5, activation='softmax')(dense_output)  # 5 sınıf örneği\n",
        "    model = Model(inputs=[bert_input_ids, bert_attention_mask, lstm_input], outputs=final_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Adım 5: Veriyi hazırlayan fonksiyon\n",
        "def prepare_dataset(data, tokenizer):\n",
        "    inputs = tokenizer(data['text'].tolist(), padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"tf\")\n",
        "    labels = tf.convert_to_tensor(data['category'].values)  # Kategorileri tensöre dönüştür\n",
        "    return inputs, labels\n",
        "\n",
        "# Adım 6: Modeli eğiten fonksiyon\n",
        "def train_ensemble_model(model, inputs, labels):\n",
        "    optimizer = Adam(learning_rate=2e-5)\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(\n",
        "        [inputs['input_ids'], inputs['attention_mask'], inputs['input_ids']],  # Hem BERT hem LSTM aynı input_ids'i kullanıyor\n",
        "        labels,\n",
        "        validation_split=0.2,\n",
        "        epochs=3,\n",
        "        batch_size=16\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Adım 7: Sonuçları raporlayan fonksiyon\n",
        "def report_results(model, inputs, labels):\n",
        "    predictions = model.predict([inputs['input_ids'], inputs['attention_mask'], inputs['input_ids']])\n",
        "    preds = predictions.argmax(axis=-1)\n",
        "    report = classification_report(labels, preds)\n",
        "    print(report)\n",
        "\n",
        "# Ana fonksiyon\n",
        "def main():\n",
        "    # Adım 1: Veri setini indirme\n",
        "    data = download_dataset()\n",
        "\n",
        "    # Adım 2: Veriyi temizleme\n",
        "    data['text'] = data['text'].apply(clean_text)\n",
        "\n",
        "    # Adım 3: Eksik değerleri doldurma\n",
        "    data = fill_missing_values(data)\n",
        "\n",
        "    # Adım 4: Tokenizer oluşturma\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    # Adım 5: Veriyi hazırlama\n",
        "    inputs, labels = prepare_dataset(data, tokenizer)\n",
        "\n",
        "    # Adım 6: Ensemble modeli oluşturma\n",
        "    ensemble_model = create_ensemble_model()\n",
        "\n",
        "    # Adım 7: Modeli eğitme\n",
        "    trained_model = train_ensemble_model(ensemble_model, inputs, labels)\n",
        "\n",
        "    # Adım 8: Sonuçları raporlama\n",
        "    report_results(trained_model, inputs, labels)\n",
        "\n",
        "# Ana fonksiyonu çağırma\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}
